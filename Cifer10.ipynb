{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10 classes. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets provides 10,000 images. This is a classification problem with 10 classes(muti-label classification). We can take a view on this image for more comprehension of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 35, 178, 235],\n",
       "         [ 40, 176, 239],\n",
       "         [ 42, 176, 241],\n",
       "         ...,\n",
       "         [ 99, 177, 219],\n",
       "         [ 79, 147, 197],\n",
       "         [ 89, 148, 189]],\n",
       "\n",
       "        [[ 57, 182, 234],\n",
       "         [ 44, 184, 250],\n",
       "         [ 50, 183, 240],\n",
       "         ...,\n",
       "         [156, 182, 200],\n",
       "         [141, 177, 206],\n",
       "         [116, 149, 175]],\n",
       "\n",
       "        [[ 98, 197, 237],\n",
       "         [ 64, 189, 252],\n",
       "         [ 69, 192, 245],\n",
       "         ...,\n",
       "         [188, 195, 206],\n",
       "         [119, 135, 147],\n",
       "         [ 61,  79,  90]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 73,  79,  77],\n",
       "         [ 53,  63,  68],\n",
       "         [ 54,  68,  80],\n",
       "         ...,\n",
       "         [ 17,  40,  64],\n",
       "         [ 21,  36,  51],\n",
       "         [ 33,  48,  49]],\n",
       "\n",
       "        [[ 61,  68,  75],\n",
       "         [ 55,  70,  86],\n",
       "         [ 57,  79, 103],\n",
       "         ...,\n",
       "         [ 24,  48,  72],\n",
       "         [ 17,  35,  53],\n",
       "         [  7,  23,  32]],\n",
       "\n",
       "        [[ 44,  56,  73],\n",
       "         [ 46,  66,  88],\n",
       "         [ 49,  77, 105],\n",
       "         ...,\n",
       "         [ 27,  52,  77],\n",
       "         [ 21,  43,  66],\n",
       "         [ 12,  31,  50]]],\n",
       "\n",
       "\n",
       "       [[[189, 211, 240],\n",
       "         [186, 208, 236],\n",
       "         [185, 207, 235],\n",
       "         ...,\n",
       "         [175, 195, 224],\n",
       "         [172, 194, 222],\n",
       "         [169, 194, 220]],\n",
       "\n",
       "        [[194, 210, 239],\n",
       "         [191, 207, 236],\n",
       "         [190, 206, 235],\n",
       "         ...,\n",
       "         [173, 192, 220],\n",
       "         [171, 191, 218],\n",
       "         [167, 190, 216]],\n",
       "\n",
       "        [[208, 219, 244],\n",
       "         [205, 216, 240],\n",
       "         [204, 215, 239],\n",
       "         ...,\n",
       "         [175, 191, 217],\n",
       "         [172, 190, 216],\n",
       "         [169, 191, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[207, 199, 181],\n",
       "         [203, 195, 175],\n",
       "         [203, 196, 173],\n",
       "         ...,\n",
       "         [135, 132, 127],\n",
       "         [162, 158, 150],\n",
       "         [168, 163, 151]],\n",
       "\n",
       "        [[198, 190, 170],\n",
       "         [189, 181, 159],\n",
       "         [180, 172, 147],\n",
       "         ...,\n",
       "         [178, 171, 160],\n",
       "         [175, 169, 156],\n",
       "         [175, 169, 154]],\n",
       "\n",
       "        [[198, 189, 173],\n",
       "         [189, 181, 162],\n",
       "         [178, 170, 149],\n",
       "         ...,\n",
       "         [195, 184, 169],\n",
       "         [196, 189, 171],\n",
       "         [195, 190, 171]]],\n",
       "\n",
       "\n",
       "       [[[229, 229, 239],\n",
       "         [236, 237, 247],\n",
       "         [234, 236, 247],\n",
       "         ...,\n",
       "         [217, 219, 233],\n",
       "         [221, 223, 234],\n",
       "         [222, 223, 233]],\n",
       "\n",
       "        [[222, 221, 229],\n",
       "         [239, 239, 249],\n",
       "         [233, 234, 246],\n",
       "         ...,\n",
       "         [223, 223, 236],\n",
       "         [227, 228, 238],\n",
       "         [210, 211, 220]],\n",
       "\n",
       "        [[213, 206, 211],\n",
       "         [234, 232, 239],\n",
       "         [231, 233, 244],\n",
       "         ...,\n",
       "         [220, 220, 232],\n",
       "         [220, 219, 232],\n",
       "         [202, 203, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[150, 143, 135],\n",
       "         [140, 135, 127],\n",
       "         [132, 127, 120],\n",
       "         ...,\n",
       "         [224, 222, 218],\n",
       "         [230, 228, 225],\n",
       "         [241, 241, 238]],\n",
       "\n",
       "        [[137, 132, 126],\n",
       "         [130, 127, 120],\n",
       "         [125, 121, 115],\n",
       "         ...,\n",
       "         [181, 180, 178],\n",
       "         [202, 201, 198],\n",
       "         [212, 211, 207]],\n",
       "\n",
       "        [[122, 119, 114],\n",
       "         [118, 116, 110],\n",
       "         [120, 116, 111],\n",
       "         ...,\n",
       "         [179, 177, 173],\n",
       "         [164, 164, 162],\n",
       "         [163, 163, 161]]]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.23137255, 0.24313726, 0.24705882],\n",
       "         [0.16862746, 0.18039216, 0.1764706 ],\n",
       "         [0.19607843, 0.1882353 , 0.16862746],\n",
       "         ...,\n",
       "         [0.61960787, 0.5176471 , 0.42352942],\n",
       "         [0.59607846, 0.49019608, 0.4       ],\n",
       "         [0.5803922 , 0.4862745 , 0.40392157]],\n",
       "\n",
       "        [[0.0627451 , 0.07843138, 0.07843138],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509805, 0.21568628],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117648, 0.22352941]],\n",
       "\n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215687, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941177, 0.19607843],\n",
       "         [0.47058824, 0.32941177, 0.19607843],\n",
       "         [0.42745098, 0.28627452, 0.16470589]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
       "         [0.7882353 , 0.6       , 0.13333334],\n",
       "         [0.7764706 , 0.6313726 , 0.10196079],\n",
       "         ...,\n",
       "         [0.627451  , 0.52156866, 0.27450982],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333334, 0.07843138]],\n",
       "\n",
       "        [[0.7058824 , 0.54509807, 0.3764706 ],\n",
       "         [0.6784314 , 0.48235294, 0.16470589],\n",
       "         [0.7294118 , 0.5647059 , 0.11764706],\n",
       "         ...,\n",
       "         [0.72156864, 0.5803922 , 0.36862746],\n",
       "         [0.38039216, 0.24313726, 0.13333334],\n",
       "         [0.3254902 , 0.20784314, 0.13333334]],\n",
       "\n",
       "        [[0.69411767, 0.5647059 , 0.45490196],\n",
       "         [0.65882355, 0.5058824 , 0.36862746],\n",
       "         [0.7019608 , 0.5568628 , 0.34117648],\n",
       "         ...,\n",
       "         [0.84705883, 0.72156864, 0.54901963],\n",
       "         [0.5921569 , 0.4627451 , 0.32941177],\n",
       "         [0.48235294, 0.36078432, 0.28235295]]],\n",
       "\n",
       "\n",
       "       [[[0.6039216 , 0.69411767, 0.73333335],\n",
       "         [0.49411765, 0.5372549 , 0.53333336],\n",
       "         [0.4117647 , 0.40784314, 0.37254903],\n",
       "         ...,\n",
       "         [0.35686275, 0.37254903, 0.2784314 ],\n",
       "         [0.34117648, 0.3529412 , 0.2784314 ],\n",
       "         [0.30980393, 0.31764707, 0.27450982]],\n",
       "\n",
       "        [[0.54901963, 0.627451  , 0.6627451 ],\n",
       "         [0.5686275 , 0.6       , 0.6039216 ],\n",
       "         [0.49019608, 0.49019608, 0.4627451 ],\n",
       "         ...,\n",
       "         [0.3764706 , 0.3882353 , 0.30588236],\n",
       "         [0.3019608 , 0.3137255 , 0.24313726],\n",
       "         [0.2784314 , 0.28627452, 0.23921569]],\n",
       "\n",
       "        [[0.54901963, 0.60784316, 0.6431373 ],\n",
       "         [0.54509807, 0.57254905, 0.58431375],\n",
       "         [0.4509804 , 0.4509804 , 0.4392157 ],\n",
       "         ...,\n",
       "         [0.30980393, 0.32156864, 0.2509804 ],\n",
       "         [0.26666668, 0.27450982, 0.21568628],\n",
       "         [0.2627451 , 0.27058825, 0.21568628]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6862745 , 0.654902  , 0.6509804 ],\n",
       "         [0.6117647 , 0.6039216 , 0.627451  ],\n",
       "         [0.6039216 , 0.627451  , 0.6666667 ],\n",
       "         ...,\n",
       "         [0.16470589, 0.13333334, 0.14117648],\n",
       "         [0.23921569, 0.20784314, 0.22352941],\n",
       "         [0.3647059 , 0.3254902 , 0.35686275]],\n",
       "\n",
       "        [[0.64705884, 0.6039216 , 0.5019608 ],\n",
       "         [0.6117647 , 0.59607846, 0.50980395],\n",
       "         [0.62352943, 0.6313726 , 0.5568628 ],\n",
       "         ...,\n",
       "         [0.40392157, 0.3647059 , 0.3764706 ],\n",
       "         [0.48235294, 0.44705883, 0.47058824],\n",
       "         [0.5137255 , 0.4745098 , 0.5137255 ]],\n",
       "\n",
       "        [[0.6392157 , 0.5803922 , 0.47058824],\n",
       "         [0.61960787, 0.5803922 , 0.47843137],\n",
       "         [0.6392157 , 0.6117647 , 0.52156866],\n",
       "         ...,\n",
       "         [0.56078434, 0.52156866, 0.54509807],\n",
       "         [0.56078434, 0.5254902 , 0.5568628 ],\n",
       "         [0.56078434, 0.52156866, 0.5647059 ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44313726, 0.47058824, 0.4392157 ],\n",
       "         [0.43529412, 0.4627451 , 0.43529412],\n",
       "         [0.4117647 , 0.4392157 , 0.41568628],\n",
       "         ...,\n",
       "         [0.28235295, 0.31764707, 0.3137255 ],\n",
       "         [0.28235295, 0.3137255 , 0.30980393],\n",
       "         [0.28235295, 0.3137255 , 0.30980393]],\n",
       "\n",
       "        [[0.43529412, 0.4627451 , 0.43137255],\n",
       "         [0.40784314, 0.43529412, 0.40784314],\n",
       "         [0.3882353 , 0.41568628, 0.38431373],\n",
       "         ...,\n",
       "         [0.26666668, 0.29411766, 0.28627452],\n",
       "         [0.27450982, 0.29803923, 0.29411766],\n",
       "         [0.30588236, 0.32941177, 0.32156864]],\n",
       "\n",
       "        [[0.41568628, 0.44313726, 0.4117647 ],\n",
       "         [0.3882353 , 0.41568628, 0.38431373],\n",
       "         [0.37254903, 0.4       , 0.36862746],\n",
       "         ...,\n",
       "         [0.30588236, 0.33333334, 0.3254902 ],\n",
       "         [0.30980393, 0.33333334, 0.3254902 ],\n",
       "         [0.3137255 , 0.3372549 , 0.32941177]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.13725491, 0.69803923, 0.92156863],\n",
       "         [0.15686275, 0.6901961 , 0.9372549 ],\n",
       "         [0.16470589, 0.6901961 , 0.94509804],\n",
       "         ...,\n",
       "         [0.3882353 , 0.69411767, 0.85882354],\n",
       "         [0.30980393, 0.5764706 , 0.77254903],\n",
       "         [0.34901962, 0.5803922 , 0.7411765 ]],\n",
       "\n",
       "        [[0.22352941, 0.7137255 , 0.91764706],\n",
       "         [0.17254902, 0.72156864, 0.98039216],\n",
       "         [0.19607843, 0.7176471 , 0.9411765 ],\n",
       "         ...,\n",
       "         [0.6117647 , 0.7137255 , 0.78431374],\n",
       "         [0.5529412 , 0.69411767, 0.80784315],\n",
       "         [0.45490196, 0.58431375, 0.6862745 ]],\n",
       "\n",
       "        [[0.38431373, 0.77254903, 0.92941177],\n",
       "         [0.2509804 , 0.7411765 , 0.9882353 ],\n",
       "         [0.27058825, 0.7529412 , 0.9607843 ],\n",
       "         ...,\n",
       "         [0.7372549 , 0.7647059 , 0.80784315],\n",
       "         [0.46666667, 0.5294118 , 0.5764706 ],\n",
       "         [0.23921569, 0.30980393, 0.3529412 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28627452, 0.30980393, 0.3019608 ],\n",
       "         [0.20784314, 0.24705882, 0.26666668],\n",
       "         [0.21176471, 0.26666668, 0.3137255 ],\n",
       "         ...,\n",
       "         [0.06666667, 0.15686275, 0.2509804 ],\n",
       "         [0.08235294, 0.14117648, 0.2       ],\n",
       "         [0.12941177, 0.1882353 , 0.19215687]],\n",
       "\n",
       "        [[0.23921569, 0.26666668, 0.29411766],\n",
       "         [0.21568628, 0.27450982, 0.3372549 ],\n",
       "         [0.22352941, 0.30980393, 0.40392157],\n",
       "         ...,\n",
       "         [0.09411765, 0.1882353 , 0.28235295],\n",
       "         [0.06666667, 0.13725491, 0.20784314],\n",
       "         [0.02745098, 0.09019608, 0.1254902 ]],\n",
       "\n",
       "        [[0.17254902, 0.21960784, 0.28627452],\n",
       "         [0.18039216, 0.25882354, 0.34509805],\n",
       "         [0.19215687, 0.3019608 , 0.4117647 ],\n",
       "         ...,\n",
       "         [0.10588235, 0.20392157, 0.3019608 ],\n",
       "         [0.08235294, 0.16862746, 0.25882354],\n",
       "         [0.04705882, 0.12156863, 0.19607843]]],\n",
       "\n",
       "\n",
       "       [[[0.7411765 , 0.827451  , 0.9411765 ],\n",
       "         [0.7294118 , 0.8156863 , 0.9254902 ],\n",
       "         [0.7254902 , 0.8117647 , 0.92156863],\n",
       "         ...,\n",
       "         [0.6862745 , 0.7647059 , 0.8784314 ],\n",
       "         [0.6745098 , 0.7607843 , 0.87058824],\n",
       "         [0.6627451 , 0.7607843 , 0.8627451 ]],\n",
       "\n",
       "        [[0.7607843 , 0.8235294 , 0.9372549 ],\n",
       "         [0.7490196 , 0.8117647 , 0.9254902 ],\n",
       "         [0.74509805, 0.80784315, 0.92156863],\n",
       "         ...,\n",
       "         [0.6784314 , 0.7529412 , 0.8627451 ],\n",
       "         [0.67058825, 0.7490196 , 0.85490197],\n",
       "         [0.654902  , 0.74509805, 0.84705883]],\n",
       "\n",
       "        [[0.8156863 , 0.85882354, 0.95686275],\n",
       "         [0.8039216 , 0.84705883, 0.9411765 ],\n",
       "         [0.8       , 0.84313726, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.6862745 , 0.7490196 , 0.8509804 ],\n",
       "         [0.6745098 , 0.74509805, 0.84705883],\n",
       "         [0.6627451 , 0.7490196 , 0.84313726]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8117647 , 0.78039217, 0.70980394],\n",
       "         [0.79607844, 0.7647059 , 0.6862745 ],\n",
       "         [0.79607844, 0.76862746, 0.6784314 ],\n",
       "         ...,\n",
       "         [0.5294118 , 0.5176471 , 0.49803922],\n",
       "         [0.63529414, 0.61960787, 0.5882353 ],\n",
       "         [0.65882355, 0.6392157 , 0.5921569 ]],\n",
       "\n",
       "        [[0.7764706 , 0.74509805, 0.6666667 ],\n",
       "         [0.7411765 , 0.70980394, 0.62352943],\n",
       "         [0.7058824 , 0.6745098 , 0.5764706 ],\n",
       "         ...,\n",
       "         [0.69803923, 0.67058825, 0.627451  ],\n",
       "         [0.6862745 , 0.6627451 , 0.6117647 ],\n",
       "         [0.6862745 , 0.6627451 , 0.6039216 ]],\n",
       "\n",
       "        [[0.7764706 , 0.7411765 , 0.6784314 ],\n",
       "         [0.7411765 , 0.70980394, 0.63529414],\n",
       "         [0.69803923, 0.6666667 , 0.58431375],\n",
       "         ...,\n",
       "         [0.7647059 , 0.72156864, 0.6627451 ],\n",
       "         [0.76862746, 0.7411765 , 0.67058825],\n",
       "         [0.7647059 , 0.74509805, 0.67058825]]],\n",
       "\n",
       "\n",
       "       [[[0.8980392 , 0.8980392 , 0.9372549 ],\n",
       "         [0.9254902 , 0.92941177, 0.96862745],\n",
       "         [0.91764706, 0.9254902 , 0.96862745],\n",
       "         ...,\n",
       "         [0.8509804 , 0.85882354, 0.9137255 ],\n",
       "         [0.8666667 , 0.8745098 , 0.91764706],\n",
       "         [0.87058824, 0.8745098 , 0.9137255 ]],\n",
       "\n",
       "        [[0.87058824, 0.8666667 , 0.8980392 ],\n",
       "         [0.9372549 , 0.9372549 , 0.9764706 ],\n",
       "         [0.9137255 , 0.91764706, 0.9647059 ],\n",
       "         ...,\n",
       "         [0.8745098 , 0.8745098 , 0.9254902 ],\n",
       "         [0.8901961 , 0.89411765, 0.93333334],\n",
       "         [0.8235294 , 0.827451  , 0.8627451 ]],\n",
       "\n",
       "        [[0.8352941 , 0.80784315, 0.827451  ],\n",
       "         [0.91764706, 0.9098039 , 0.9372549 ],\n",
       "         [0.90588236, 0.9137255 , 0.95686275],\n",
       "         ...,\n",
       "         [0.8627451 , 0.8627451 , 0.9098039 ],\n",
       "         [0.8627451 , 0.85882354, 0.9098039 ],\n",
       "         [0.7921569 , 0.79607844, 0.84313726]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5882353 , 0.56078434, 0.5294118 ],\n",
       "         [0.54901963, 0.5294118 , 0.49803922],\n",
       "         [0.5176471 , 0.49803922, 0.47058824],\n",
       "         ...,\n",
       "         [0.8784314 , 0.87058824, 0.85490197],\n",
       "         [0.9019608 , 0.89411765, 0.88235295],\n",
       "         [0.94509804, 0.94509804, 0.93333334]],\n",
       "\n",
       "        [[0.5372549 , 0.5176471 , 0.49411765],\n",
       "         [0.50980395, 0.49803922, 0.47058824],\n",
       "         [0.49019608, 0.4745098 , 0.4509804 ],\n",
       "         ...,\n",
       "         [0.70980394, 0.7058824 , 0.69803923],\n",
       "         [0.7921569 , 0.7882353 , 0.7764706 ],\n",
       "         [0.83137256, 0.827451  , 0.8117647 ]],\n",
       "\n",
       "        [[0.47843137, 0.46666667, 0.44705883],\n",
       "         [0.4627451 , 0.45490196, 0.43137255],\n",
       "         [0.47058824, 0.45490196, 0.43529412],\n",
       "         ...,\n",
       "         [0.7019608 , 0.69411767, 0.6784314 ],\n",
       "         [0.6431373 , 0.6431373 , 0.63529414],\n",
       "         [0.6392157 , 0.6392157 , 0.6313726 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Defining the model using ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first stage, Our net will learn 32 convolutional filters, each of which with a 3 x 3 size. The output dimension is the same one of the input shape, so it will be 32 x 32 and activation is relu, which is a simple way of introducing non-linearity; folowed by another 32 convolutional filters, each of which with a 3 x 3 size and activation is also relu. After that we have a max-pooling operation with pool size 2 x 2 and a dropout at 25%.\n",
    "\n",
    "In the next stage in the deep pipeline, Our net will learn 64 convolutional filters, each of which with a 3 x 3 size. The output dimension is the same one of the input shape and activation is relu; folowed by another 64 convolutional filters, each of which with a 3 x 3 size and activation is also relu. After that we have a max-pooling operation with pool size 2 x 2 and a dropout at 25%.\n",
    "\n",
    "And the Final stage in the deep pipeline is a dense network with 512 units and relu activation followed by a dropout at 50% and by a softmax layer with 10 classes as output, one for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding='same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(MaxPooling2D(3,strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(MaxPooling2D(3,strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(MaxPooling2D(3,strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 358,186\n",
      "Trainable params: 358,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train the model, we will add:\n",
    "    1. Loss function to measure how good is the network.\n",
    "    2. An Optimizer: to update the network\n",
    "    3. Metrics: to monitor performance of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(\n",
    "    learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 272s 690ms/step - loss: 1.8991 - accuracy: 0.2849 - val_loss: 1.2269 - val_accuracy: 0.5551\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 271s 694ms/step - loss: 1.2184 - accuracy: 0.5637 - val_loss: 0.9932 - val_accuracy: 0.6475\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 243s 623ms/step - loss: 0.9940 - accuracy: 0.6466 - val_loss: 0.8503 - val_accuracy: 0.6973\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 231s 591ms/step - loss: 0.8670 - accuracy: 0.6955 - val_loss: 0.9207 - val_accuracy: 0.6825\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 243s 622ms/step - loss: 0.7826 - accuracy: 0.7293 - val_loss: 0.7263 - val_accuracy: 0.7501\n"
     ]
    }
   ],
   "source": [
    "model = model.fit(x_train,y_train,\n",
    "                   batch_size=128,\n",
    "                   epochs=5,\n",
    "                   validation_data=(x_test,y_test),\n",
    "                   shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-419f9b57acae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
